{"cells":[{"cell_type":"code","execution_count":51,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":6130,"status":"ok","timestamp":1747737701628,"user":{"displayName":"At K","userId":"15418626898878558921"},"user_tz":-540},"id":"79XPcw9vDW4y","outputId":"65edb92d-7f2b-4fd0-a9a7-0c2de324b633"},"outputs":[{"name":"stdout","output_type":"stream","text":["▶️ セル1: 環境設定 を開始します...\n","Requirement already satisfied: google-cloud-texttospeech in /usr/local/lib/python3.11/dist-packages (2.27.0)\n","Requirement already satisfied: python-dotenv in /usr/local/lib/python3.11/dist-packages (1.1.0)\n","Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,\u003c3.0.0,\u003e=1.34.1 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,\u003c3.0.0,\u003e=1.34.1-\u003egoogle-cloud-texttospeech) (2.24.2)\n","Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,\u003c3.0.0,\u003e=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google-cloud-texttospeech) (2.38.0)\n","Requirement already satisfied: proto-plus\u003c2.0.0,\u003e=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-cloud-texttospeech) (1.26.1)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,\u003c7.0.0,\u003e=3.20.2 in /usr/local/lib/python3.11/dist-packages (from google-cloud-texttospeech) (5.29.4)\n","Requirement already satisfied: googleapis-common-protos\u003c2.0.0,\u003e=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,\u003c3.0.0,\u003e=1.34.1-\u003egoogle-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,\u003c3.0.0,\u003e=1.34.1-\u003egoogle-cloud-texttospeech) (1.70.0)\n","Requirement already satisfied: requests\u003c3.0.0,\u003e=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,\u003c3.0.0,\u003e=1.34.1-\u003egoogle-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,\u003c3.0.0,\u003e=1.34.1-\u003egoogle-cloud-texttospeech) (2.32.3)\n","Requirement already satisfied: grpcio\u003c2.0dev,\u003e=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,\u003c3.0.0,\u003e=1.34.1-\u003egoogle-cloud-texttospeech) (1.71.0)\n","Requirement already satisfied: grpcio-status\u003c2.0.dev0,\u003e=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,\u003c3.0.0,\u003e=1.34.1-\u003egoogle-cloud-texttospeech) (1.71.0)\n","Requirement already satisfied: cachetools\u003c6.0,\u003e=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,\u003c3.0.0,\u003e=2.14.1-\u003egoogle-cloud-texttospeech) (5.5.2)\n","Requirement already satisfied: pyasn1-modules\u003e=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,\u003c3.0.0,\u003e=2.14.1-\u003egoogle-cloud-texttospeech) (0.4.2)\n","Requirement already satisfied: rsa\u003c5,\u003e=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,\u003c3.0.0,\u003e=2.14.1-\u003egoogle-cloud-texttospeech) (4.9.1)\n","Requirement already satisfied: pyasn1\u003c0.7.0,\u003e=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules\u003e=0.2.1-\u003egoogle-auth!=2.24.0,!=2.25.0,\u003c3.0.0,\u003e=2.14.1-\u003egoogle-cloud-texttospeech) (0.6.1)\n","Requirement already satisfied: charset-normalizer\u003c4,\u003e=2 in /usr/local/lib/python3.11/dist-packages (from requests\u003c3.0.0,\u003e=2.18.0-\u003egoogle-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,\u003c3.0.0,\u003e=1.34.1-\u003egoogle-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,\u003c3.0.0,\u003e=1.34.1-\u003egoogle-cloud-texttospeech) (3.4.2)\n","Requirement already satisfied: idna\u003c4,\u003e=2.5 in /usr/local/lib/python3.11/dist-packages (from requests\u003c3.0.0,\u003e=2.18.0-\u003egoogle-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,\u003c3.0.0,\u003e=1.34.1-\u003egoogle-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,\u003c3.0.0,\u003e=1.34.1-\u003egoogle-cloud-texttospeech) (3.10)\n","Requirement already satisfied: urllib3\u003c3,\u003e=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests\u003c3.0.0,\u003e=2.18.0-\u003egoogle-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,\u003c3.0.0,\u003e=1.34.1-\u003egoogle-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,\u003c3.0.0,\u003e=1.34.1-\u003egoogle-cloud-texttospeech) (2.4.0)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests\u003c3.0.0,\u003e=2.18.0-\u003egoogle-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,\u003c3.0.0,\u003e=1.34.1-\u003egoogle-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,\u003c3.0.0,\u003e=1.34.1-\u003egoogle-cloud-texttospeech) (2025.4.26)\n","Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (0.25.1)\n","✅ セル1: 環境設定が完了しました。\n"]}],"source":["# ========== セル 1: 環境設定 (ライブラリインストール) ==========\n","# 目的: このノートブックで必要なPythonライブラリをインストールします。\n","\n","print(\"▶️ セル1: 環境設定 を開始します...\")\n","# google-cloud-texttospeech: Google Cloud Text-to-Speech APIを利用するためのライブラリ\n","# python-dotenv: .envファイルから環境変数を読み込むため (今回はサービスアカウントキー優先なので厳密には不要)\n","!pip install --upgrade google-cloud-texttospeech python-dotenv\n","!pip install pydub\n","\n","print(\"✅ セル1: 環境設定が完了しました。\")"]},{"cell_type":"code","execution_count":65,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4143,"status":"ok","timestamp":1747738635751,"user":{"displayName":"At K","userId":"15418626898878558921"},"user_tz":-540},"id":"1YkUhgOHDcx-","outputId":"4ada25ef-a600-4e4c-dd0e-8ee7d2e17672"},"outputs":[{"name":"stdout","output_type":"stream","text":["▶️ セル2: Imports, Constants, Authentication, and Client Setup を開始します...\n","   ✅ 主要ライブラリをインポートしました。\n","Mounted at /content/drive\n","   ✅ Google Drive マウント成功。DRIVE_ROOT: /content/drive/MyDrive/Colab Notebooks/00_Podcast/yt_podcast\n","   ✅ 環境変数 GOOGLE_APPLICATION_CREDENTIALS にSAキー設定: /content/drive/MyDrive/Colab Notebooks/00_Podcast/yt_podcast/Key/gen-lang-client-0377684772-09447c306d22.json\n","   ✅ Text-to-Speech クライアント初期化成功。\n","   ℹ️ 台本入力ディレクトリ: /content/drive/MyDrive/Colab Notebooks/00_Podcast/yt_podcast/scripts\n","   ℹ️ 音声出力ディレクトリ: /content/drive/MyDrive/Colab Notebooks/00_Podcast/yt_podcast/outputs\n","   ✅ キャラクターボイス設定を定義しました。\n","   ✅ オーディオ設定 (MP3) を定義しました。\n","✅ セル2: Imports, Constants, Authentication, and Client Setup が完了しました。\n"]}],"source":["# ========== セル 2: Imports, Constants, Authentication, and Client Setup ==========\n","print(\"▶️ セル2: Imports, Constants, Authentication, and Client Setup を開始します...\")\n","\n","# ─── 1. ライブラリのインポート ───\n","import os\n","import html\n","import time\n","import io\n","from google.colab import drive\n","from google.cloud import texttospeech_v1 as texttospeech\n","import pandas as pd\n","try:\n","    from pydub import AudioSegment\n","except ImportError:\n","    print(\"‼️警告: pydubライブラリが見つかりません。\"); AudioSegment = None\n","print(\"   ✅ 主要ライブラリをインポートしました。\")\n","\n","# ─── 2. Google DriveのマウントとDRIVE_ROOT設定 ───\n","DRIVE_ROOT = None\n","try:\n","    drive.mount('/content/drive', force_remount=True)\n","    DRIVE_ROOT = \"/content/drive/MyDrive/Colab Notebooks/00_Podcast/yt_podcast\"\n","    if not os.path.isdir(DRIVE_ROOT):\n","        print(f\"‼️エラー: DRIVE_ROOTパス不正: {DRIVE_ROOT}\")\n","        DRIVE_ROOT = None\n","    else:\n","        print(f\"   ✅ Google Drive マウント成功。DRIVE_ROOT: {DRIVE_ROOT}\")\n","except Exception as e:\n","    print(f\"‼️エラー: Driveマウント失敗: {e}\")\n","    DRIVE_ROOT = None\n","\n","# ─── 3. サービスアカウントキーJSONファイルの設定と認証 ───\n","SERVICE_ACCOUNT_KEY_FILENAME = \"gen-lang-client-0377684772-09447c306d22.json\"\n","TTS_CLIENT_INITIALIZED = False\n","tts_client = None\n","if DRIVE_ROOT:\n","    key_directory = os.path.join(DRIVE_ROOT, \"Key\")\n","    SERVICE_ACCOUNT_KEY_PATH = os.path.join(key_directory, SERVICE_ACCOUNT_KEY_FILENAME)\n","    if os.path.exists(SERVICE_ACCOUNT_KEY_PATH):\n","        os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = SERVICE_ACCOUNT_KEY_PATH\n","        print(f\"   ✅ 環境変数 GOOGLE_APPLICATION_CREDENTIALS にSAキー設定: {SERVICE_ACCOUNT_KEY_PATH}\")\n","        try:\n","            tts_client = texttospeech.TextToSpeechClient()\n","            print(\"   ✅ Text-to-Speech クライアント初期化成功。\")\n","            TTS_CLIENT_INITIALIZED = True\n","        except Exception as e:\n","            print(f\"‼️エラー: TTSクライアント初期化失敗: {e}\")\n","    else:\n","        print(f\"‼️エラー: SAキーファイルが見つかりません: {SERVICE_ACCOUNT_KEY_PATH}\")\n","else:\n","    print(\"‼️エラー: DRIVE_ROOT が無効なため、SAキーパス設定不可。\")\n","\n","# ─── 4. 関連ディレクトリパスの定義・確認 ───\n","if DRIVE_ROOT:\n","    SCRIPTS_DIR_TTS = os.path.join(DRIVE_ROOT, \"scripts\")\n","    OUTPUTS_DIR_TTS = os.path.join(DRIVE_ROOT, \"outputs\")\n","    os.makedirs(OUTPUTS_DIR_TTS, exist_ok=True)\n","    print(f\"   ℹ️ 台本入力ディレクトリ: {SCRIPTS_DIR_TTS}\")\n","    print(f\"   ℹ️ 音声出力ディレクトリ: {OUTPUTS_DIR_TTS}\")\n","else:\n","    SCRIPTS_DIR_TTS = OUTPUTS_DIR_TTS = None\n","\n","# ─── 5. キャラクターボイス設定 ───\n","VOICE_SETTINGS = {\n","    'Maya': texttospeech.VoiceSelectionParams(\n","        language_code='ja-JP',\n","        name='ja-JP-Neural2-B'    # Mayaはこれまで通り\n","    ),\n","    'Shiba': texttospeech.VoiceSelectionParams(\n","        language_code='ja-JP',\n","        name='ja-JP-Neural2-C'    # 存在が確認できたCに変更\n","    ),\n","    'Default': texttospeech.VoiceSelectionParams(\n","        language_code='ja-JP'     # nameを外してlanguage_codeのみ\n","    )\n","}\n","print(\"   ✅ キャラクターボイス設定を定義しました。\")\n","\n","# ─── 6. オーディオ設定 ───\n","AUDIO_CONFIG_MP3 = texttospeech.AudioConfig(\n","    audio_encoding=texttospeech.AudioEncoding.MP3,\n","    speaking_rate=1.0,\n","    pitch=0.0\n",")\n","print(\"   ✅ オーディオ設定 (MP3) を定義しました。\")\n","\n","print(\"✅ セル2: Imports, Constants, Authentication, and Client Setup が完了しました。\")\n"]},{"cell_type":"code","execution_count":66,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1886,"status":"ok","timestamp":1747738640224,"user":{"displayName":"At K","userId":"15418626898878558921"},"user_tz":-540},"id":"Tx2DcxI2DdK8","outputId":"d2932f2c-0206-4971-fb92-a7e5c9d853e8"},"outputs":[{"name":"stdout","output_type":"stream","text":["▶️ セル3: スピーカー別の音声合成テストを開始します...\n","   ℹ️ テスト対象: 433nP6kGRbQ.txt (Video ID: 433nP6kGRbQ)\n","   💬 セグメント 1: voice=ja-JP-Neural2-B, text='こんにちは、マヤです。…'\n","   💬 セグメント 2: voice=ja-JP-Neural2-C, text='こんにちは、シバわん！…'\n","   💬 セグメント 3: voice=ja-JP-Neural2-B, text='これはテスト音声です。…'\n","   💬 セグメント 4: voice=ja-JP-Neural2-C, text='うまくいくかな？わくわく！…'\n","   🔗 4 個のチャンクを結合中...\n","✅ 合成完了: /content/drive/MyDrive/Colab Notebooks/00_Podcast/yt_podcast/outputs/433nP6kGRbQ_speaker_test.mp3\n","✅ セル3: テスト実行 完了しました。\n"]}],"source":["# ========== セル 3: STEP5 テスト実行 (スピーカー別 API 呼び出し方式) ==========\n","print(\"▶️ セル3: スピーカー別の音声合成テストを開始します...\")\n","\n","from google.cloud import texttospeech_v1 as texttospeech\n","import io\n","import os\n","from pydub import AudioSegment\n","\n","# --- ヘルパー関数: テキスト＋VoiceSelectionParams で合成 ---\n","def synthesize_text_for_tts(text, voice_params, audio_config, client):\n","    # テキスト入力を使うことで SSML の \u003cvoice\u003e タグ不要に\n","    synthesis_input = texttospeech.SynthesisInput(text=text)\n","    response = client.synthesize_speech(\n","        request={\n","            \"input\": synthesis_input,\n","            \"voice\": voice_params,\n","            \"audio_config\": audio_config,\n","        }\n","    )\n","    return response.audio_content\n","\n","# --- テスト用: 最初の台本ファイルを読み込み ---\n","script_files = sorted([f for f in os.listdir(SCRIPTS_DIR_TTS) if f.endswith('.txt')])\n","if not script_files:\n","    print(\"‼️ テスト用の台本ファイルが見つかりません。セル2でパスを確認してください。\")\n","else:\n","    src = script_files[0]\n","    vid = src[:-4]\n","    print(f\"   ℹ️ テスト対象: {src} (Video ID: {vid})\")\n","    lines = []\n","    with open(os.path.join(SCRIPTS_DIR_TTS, src), encoding='utf-8') as f:\n","        for raw in f:\n","            line = raw.strip()\n","            if line:\n","                lines.append(line)\n","\n","    # --- 台本を行ごとに \"(テキスト, VoiceSelectionParams)\" のリストに変換 ---\n","    segments = []\n","    current_speaker = 'Default'\n","    for line in lines:\n","        if ':' in line:\n","            tag, content = line.split(':', 1)\n","            tag = tag.strip()\n","            if tag in VOICE_SETTINGS:\n","                current_speaker = tag\n","                text = content.strip()\n","            else:\n","                text = line\n","        else:\n","            text = line\n","        # 話者タグに対応する voice パラメータを取得\n","        voice_params = VOICE_SETTINGS.get(current_speaker, VOICE_SETTINGS['Default'])\n","        segments.append((text, voice_params))\n","\n","    # --- 各セグメントを合成して結合 ---\n","    audio_list = []\n","    for idx, (txt, vp) in enumerate(segments, 1):\n","        print(f\"   💬 セグメント {idx}: voice={vp.name}, text='{txt[:20]}…'\")\n","        audio_bytes = synthesize_text_for_tts(txt, vp, AUDIO_CONFIG_MP3, tts_client)\n","        audio_list.append(AudioSegment.from_file(io.BytesIO(audio_bytes), format='mp3'))\n","\n","    print(f\"   🔗 {len(audio_list)} 個のチャンクを結合中...\")\n","    combined = AudioSegment.empty()\n","    for seg in audio_list:\n","        combined += seg\n","\n","    # --- 出力 ---\n","    out_fn = f\"{vid}_speaker_test.mp3\"\n","    out_path = os.path.join(OUTPUTS_DIR_TTS, out_fn)\n","    combined.export(out_path, format='mp3')\n","    print(f\"✅ 合成完了: {out_path}\")\n","\n","print(\"✅ セル3: テスト実行 完了しました。\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"Y3m8zL_KTX5D"},"outputs":[{"name":"stdout","output_type":"stream","text":["▶️ セル4: 本番実行を開始します...\n","\n","   ▶️ 処理中: 433nP6kGRbQ.txt → 433nP6kGRbQ.mp3\n","      🔉 セグメント1: voice=ja-JP-Neural2-B, text='こんにちは、マヤです。…'\n","      🔉 セグメント2: voice=ja-JP-Neural2-C, text='こんにちは、シバわん！…'\n","      🔉 セグメント3: voice=ja-JP-Neural2-B, text='これはテスト音声です。…'\n","      🔉 セグメント4: voice=ja-JP-Neural2-C, text='うまくいくかな？わくわく！…'\n","      🔗 4 チャンクを結合中...\n","   ✅ 出力完了: /content/drive/MyDrive/Colab Notebooks/00_Podcast/yt_podcast/outputs/433nP6kGRbQ.mp3\n","\n","   ▶️ 処理中: G3fjxgYCct0.txt → G3fjxgYCct0.mp3\n","      🔉 セグメント1: voice=ja-JP, text='```…'\n","      🔉 セグメント2: voice=ja-JP-Neural2-B, text='皆さん、こんにちは！今日のポッドキャスト…'\n","      🔉 セグメント3: voice=ja-JP-Neural2-C, text='わーい！Mayaお姉ちゃん、今日はどんな…'\n","      🔉 セグメント4: voice=ja-JP-Neural2-B, text='大丈夫ですよ、Shibaちゃん。難しい言…'\n","      🔉 セグメント5: voice=ja-JP-Neural2-C, text='うん！…'\n","      🔉 セグメント6: voice=ja-JP-Neural2-B, text='まず一つ目は、「マーケティングは、量より…'\n","      🔉 セグメント7: voice=ja-JP-Neural2-C, text='それってどういうこと？たくさん宣伝した方…'\n","      🔉 セグメント8: voice=ja-JP-Neural2-B, text='確かに、量をこなすことも重要ですが、それ…'\n","      🔉 セグメント9: voice=ja-JP-Neural2-C, text='くぅ～ん、なるほどね！それってつまり、押…'\n","      🔉 セグメント10: voice=ja-JP-Neural2-B, text='その通りです。…'\n","      🔉 セグメント11: voice=ja-JP-Neural2-B, text='二つ目は、「情熱を追いかけるのではなく、…'\n","      🔉 セグメント12: voice=ja-JP-Neural2-C, text='えー、好きなことを仕事にするんじゃないの…'\n","      🔉 セグメント13: voice=ja-JP-Neural2-B, text='好きなことを仕事にするのは素晴らしいこと…'\n","      🔉 セグメント14: voice=ja-JP-Neural2-C, text='ふむふむ。スキルを磨けば、好きじゃなかっ…'\n","      🔉 セグメント15: voice=ja-JP-Neural2-B, text='そういうことですね。…'\n","      🔉 セグメント16: voice=ja-JP-Neural2-B, text='そして三つ目は、「信頼を築くために、まず…'\n","      🔉 セグメント17: voice=ja-JP-Neural2-C, text='それって、ボランティアみたいだね！ビジネ…'\n","      🔉 セグメント18: voice=ja-JP-Neural2-B, text='もちろん、ビジネスはお金を稼ぐことが目的…'\n","      🔉 セグメント19: voice=ja-JP-Neural2-C, text='なるほど！信頼って、すごく大事なんだね！…'\n","      🔉 セグメント20: voice=ja-JP-Neural2-B, text='そうですね。では、今日のまとめとして、リ…'\n","      🔉 セグメント21: voice=ja-JP-Neural2-C, text='それならShibaにもできそう！わん！…'\n","      🔉 セグメント22: voice=ja-JP-Neural2-B, text='ありがとうございます、Shibaちゃん。…'\n","      🔉 セグメント23: voice=ja-JP-Neural2-C, text='今日は、マーケティングは量より質、情熱は…'\n","      🔉 セグメント24: voice=ja-JP-Neural2-B, text='Shibaちゃんの感想、ありがとうござい…'\n","      🔉 セグメント25: voice=ja-JP-Neural2-B, text='```…'\n","      🔗 25 チャンクを結合中...\n","   ✅ 出力完了: /content/drive/MyDrive/Colab Notebooks/00_Podcast/yt_podcast/outputs/G3fjxgYCct0.mp3\n","\n","   ▶️ 処理中: MLu6Lf7Mg58.txt → MLu6Lf7Mg58.mp3\n","      🔉 セグメント1: voice=ja-JP, text='```…'\n","      🔉 セグメント2: voice=ja-JP-Neural2-B, text='皆さん、こんにちは！今日も「意識高めビジ…'\n","      🔉 セグメント3: voice=ja-JP-Neural2-C, text='わーい！Mayaお姉ちゃん、今日はどんな…'\n","      🔉 セグメント4: voice=ja-JP-Neural2-B, text='Shibaちゃん、今日も元気いっぱいね！…'\n","      🔉 セグメント5: voice=ja-JP-Neural2-C, text='3つのコツ？気になる！くぅ～ん！…'\n","      🔉 セグメント6: voice=ja-JP-Neural2-B, text='はい、まず1つ目は「起きてすぐの15分は…'\n","      🔉 セグメント7: voice=ja-JP-Neural2-C, text='思考をシャットダウン？それってどういうこ…'\n","      🔉 セグメント8: voice=ja-JP-Neural2-B, text='朝起きてすぐ、スマホをチェックしたり、ニ…'\n","      🔉 セグメント9: voice=ja-JP-Neural2-C, text='なるほど！朝から情報に溺れないようにする…'\n","      🔉 セグメント10: voice=ja-JP-Neural2-B, text='その通りです。2つ目は「その日の目標を書…'\n","      🔉 セグメント11: voice=ja-JP-Neural2-C, text='目標を書き出す？それって大事なの？…'\n","      🔉 セグメント12: voice=ja-JP-Neural2-B, text='とても大事です！1日の最初に、今日やるべ…'\n","      🔉 セグメント13: voice=ja-JP-Neural2-C, text='わぁ、すごい！目標があると、迷子にならな…'\n","      🔉 セグメント14: voice=ja-JP-Neural2-B, text='そうなんです。そして3つ目は「朝食の準備…'\n","      🔉 セグメント15: voice=ja-JP-Neural2-C, text='朝ごはん、ちゃんと食べないと力が出ないも…'\n","      🔉 セグメント16: voice=ja-JP-Neural2-B, text='その通り！動画では「完全に調理する必要は…'\n","      🔉 セグメント17: voice=ja-JP-Neural2-C, text='なるほどね！準備しておけば、ちゃんと食べ…'\n","      🔉 セグメント18: voice=ja-JP-Neural2-B, text='そうですね。さて、今日の教訓を活かして、…'\n","      🔉 セグメント19: voice=ja-JP-Neural2-C, text='それならShibaにもできそう！わん！…'\n","      🔉 セグメント20: voice=ja-JP-Neural2-B, text='ぜひ試してみてください。Shibaちゃん…'\n","      🔉 セグメント21: voice=ja-JP-Neural2-C, text='今日は朝のルーティンについて学べて、とっ…'\n","      🔉 セグメント22: voice=ja-JP-Neural2-B, text='素晴らしい！Shibaちゃん、ありがとう…'\n","      🔉 セグメント23: voice=ja-JP-Neural2-B, text='```…'\n","      🔗 23 チャンクを結合中...\n","   ✅ 出力完了: /content/drive/MyDrive/Colab Notebooks/00_Podcast/yt_podcast/outputs/MLu6Lf7Mg58.mp3\n","\n","   ▶️ 処理中: W2FjF450eZA.txt → W2FjF450eZA.mp3\n","      🔉 セグメント1: voice=ja-JP, text='```…'\n","      🔉 セグメント2: voice=ja-JP-Neural2-B, text='皆さん、こんにちは！今日も「賢く生きる！…'\n","      🔉 セグメント3: voice=ja-JP-Neural2-C, text='わーい！Mayaお姉ちゃん、今日はどんな…'\n","      🔉 セグメント4: voice=ja-JP-Neural2-B, text='そうですね、Shibaちゃん。借金と聞く…'\n","      🔉 セグメント5: voice=ja-JP-Neural2-C, text='ふむふむ。ぜひ聞きたい！…'\n","      🔉 セグメント6: voice=ja-JP-Neural2-B, text='まず、銀行の仕組みから見ていきましょう。…'\n","      🔉 セグメント7: voice=ja-JP-Neural2-C, text='え、そうなの？銀行って、お金を預かってく…'\n","      🔉 セグメント8: voice=ja-JP-Neural2-B, text='そうなんです。そして、ここが重要なポイン…'\n","      🔉 セグメント9: voice=ja-JP-Neural2-C, text='なるほど！じゃあ、ただ買い物するためにお…'\n","      🔉 セグメント10: voice=ja-JP-Neural2-B, text='その通りです。例えば、クレジットカードで…'\n","      🔉 セグメント11: voice=ja-JP-Neural2-C, text='くぅ～ん、なるほどね！それってつまり、借…'\n","      🔉 セグメント12: voice=ja-JP-Neural2-B, text='まさに、その通りです！日本の不動産投資も…'\n","      🔉 セグメント13: voice=ja-JP-Neural2-C, text='すごい！でも、もし家賃収入が減っちゃった…'\n","      🔉 セグメント14: voice=ja-JP-Neural2-B, text='良い質問ですね、Shibaちゃん。不動産…'\n","      🔉 セグメント15: voice=ja-JP-Neural2-C, text='なるほど…奥が深いなぁ。…'\n","      🔉 セグメント16: voice=ja-JP-Neural2-B, text='もう一つ重要なポイントは、借金に対する考…'\n","      🔉 セグメント17: voice=ja-JP-Neural2-C, text='ツール？…'\n","      🔉 セグメント18: voice=ja-JP-Neural2-B, text='はい。例えば、包丁は料理を作るのに欠かせ…'\n","      🔉 セグメント19: voice=ja-JP-Neural2-C, text='わん！確かにそうだね！使い方を間違えなけ…'\n","      🔉 セグメント20: voice=ja-JP-Neural2-B, text='そうなんです。では、今日のまとめとして、…'\n","      🔉 セグメント21: voice=ja-JP-Neural2-C, text='それならShibaにもできそう！まずは、…'\n","      🔉 セグメント22: voice=ja-JP-Neural2-B, text='素晴らしいですね、Shibaちゃん！小さ…'\n","      🔉 セグメント23: voice=ja-JP-Neural2-C, text='はーい！今日の話を聞いて、借金に対するイ…'\n","      🔉 セグメント24: voice=ja-JP-Neural2-B, text='ありがとうございます、Shibaちゃん。…'\n","      🔉 セグメント25: voice=ja-JP-Neural2-B, text='```…'\n","      🔗 25 チャンクを結合中...\n","   ✅ 出力完了: /content/drive/MyDrive/Colab Notebooks/00_Podcast/yt_podcast/outputs/W2FjF450eZA.mp3\n","\n","   ▶️ 処理中: ahy9Ctcn5Ko.txt → ahy9Ctcn5Ko.mp3\n","      🔉 セグメント1: voice=ja-JP, text='```…'\n","      🔉 セグメント2: voice=ja-JP-Neural2-B, text='皆さん、こんにちは！いつもポッドキャスト…'\n","      🔉 セグメント3: voice=ja-JP-Neural2-C, text='わーい！Mayaお姉ちゃん、今日はどんな…'\n","      🔉 セグメント4: voice=ja-JP-Neural2-B, text='Shibaちゃん、ありがとう。きっとSh…'\n","      🔉 セグメント5: voice=ja-JP-Neural2-C, text='改善…？それって、毎日ちょっとずつでもい…'\n","      🔉 セグメント6: voice=ja-JP-Neural2-B, text='そうなんです。日本の「改善（カイゼン）」…'\n","      🔉 セグメント7: voice=ja-JP-Neural2-C, text='くぅ～ん、なるほどね！毎日ちょっとずつな…'\n","      🔉 セグメント8: voice=ja-JP-Neural2-B, text='次の習慣は「前進」です。改善と並行して、…'\n","      🔉 セグメント9: voice=ja-JP-Neural2-C, text='前進…？でも、毎日大きな成果を出すのは難…'\n","      🔉 セグメント10: voice=ja-JP-Neural2-B, text='まさにそこがポイントなんです。多くの人が…'\n","      🔉 セグメント11: voice=ja-JP-Neural2-C, text='へぇ～、それって日本の会社でも使えるのか…'\n","      🔉 セグメント12: voice=ja-JP-Neural2-B, text='もちろん！むしろ、日本の企業文化にとても…'\n","      🔉 セグメント13: voice=ja-JP-Neural2-B, text='最後の習慣は「事前計画」です。翌日の計画…'\n","      🔉 セグメント14: voice=ja-JP-Neural2-C, text='事前計画！Shibaはいつも、おやつを食…'\n","      🔉 セグメント15: voice=ja-JP-Neural2-B, text='それは素晴らしい！ビジネスでも同じように…'\n","      🔉 セグメント16: voice=ja-JP-Neural2-C, text='わぁ、すごい！計画を立てておくと、迷わな…'\n","      🔉 セグメント17: voice=ja-JP-Neural2-B, text='そうなんです。さて、今日のまとめとして、…'\n","      🔉 セグメント18: voice=ja-JP-Neural2-C, text='それならShibaにもできそう！明日は、…'\n","      🔉 セグメント19: voice=ja-JP-Neural2-C, text='今日の話、とっても面白かった！Shiba…'\n","      🔉 セグメント20: voice=ja-JP-Neural2-B, text='Shibaちゃん、ありがとう。今日のポッ…'\n","      🔉 セグメント21: voice=ja-JP-Neural2-B, text='```…'\n","      🔗 21 チャンクを結合中...\n","   ✅ 出力完了: /content/drive/MyDrive/Colab Notebooks/00_Podcast/yt_podcast/outputs/ahy9Ctcn5Ko.mp3\n","\n","   ▶️ 処理中: aiQj19TUMYM.txt → aiQj19TUMYM.mp3\n","      🔉 セグメント1: voice=ja-JP, text='```…'\n","      🔉 セグメント2: voice=ja-JP-Neural2-B, text='皆さん、こんにちは！今日も「意識高めビジ…'\n","      🔉 セグメント3: voice=ja-JP-Neural2-C, text='わーい！Mayaお姉ちゃん、今日はどんな…'\n","      🔉 セグメント4: voice=ja-JP-Neural2-B, text='Shibaちゃん、残念ながら美味しいもの…'\n","      🔉 セグメント5: voice=ja-JP-Neural2-C, text='へぇ～！価値観って、そんなに色々なところ…'\n","      🔉 セグメント6: voice=ja-JP-Neural2-B, text='例えば、チームで仕事をする時に「協力」と…'\n","      🔉 セグメント7: voice=ja-JP-Neural2-C, text='なるほど！協力とか競争とか、会社によって…'\n","      🔉 セグメント8: voice=ja-JP-Neural2-B, text='そうなんです。そして、この動画で私が特に…'\n","      🔉 セグメント9: voice=ja-JP-Neural2-C, text='羅針盤！わん！それって、冒険みたいでかっ…'\n","      🔉 セグメント10: voice=ja-JP-Neural2-B, text='いい質問ですね、Shibaちゃん。価値観…'\n","      🔉 セグメント11: voice=ja-JP-Neural2-C, text='なるほど！自分の好きなこととか、嫌なこと…'\n","      🔉 セグメント12: voice=ja-JP-Neural2-B, text='そうなんです。そして2つ目のポイントは、…'\n","      🔉 セグメント13: voice=ja-JP-Neural2-C, text='行動の原動力！わん！それって、ゲームの必…'\n","      🔉 セグメント14: voice=ja-JP-Neural2-B, text='確かに！（笑）例えば、環境保護を大切に思…'\n","      🔉 セグメント15: voice=ja-JP-Neural2-C, text='共通の価値観！それって、友達と好きなもの…'\n","      🔉 セグメント16: voice=ja-JP-Neural2-B, text='そうですね、まさにその通りです。価値観が…'\n","      🔉 セグメント17: voice=ja-JP-Neural2-C, text='価値観って、本当に色々なところに影響して…'\n","      🔉 セグメント18: voice=ja-JP-Neural2-B, text='そうなんです。だからこそ、自分の価値観を…'\n","      🔉 セグメント19: voice=ja-JP-Neural2-C, text='価値観リスト！それならShibaにもでき…'\n","      🔉 セグメント20: voice=ja-JP-Neural2-B, text='素晴らしいですね！Shibaちゃん。…'\n","      🔉 セグメント21: voice=ja-JP-Neural2-C, text='今日のお話を聞いて、価値観ってなんだか人…'\n","      🔉 セグメント22: voice=ja-JP-Neural2-B, text='素敵な感想ですね、Shibaちゃん。リス…'\n","      🔉 セグメント23: voice=ja-JP-Neural2-B, text='```…'\n","      🔗 23 チャンクを結合中...\n","   ✅ 出力完了: /content/drive/MyDrive/Colab Notebooks/00_Podcast/yt_podcast/outputs/aiQj19TUMYM.mp3\n","\n","   ▶️ 処理中: h79B1Z4Bwyw.txt → h79B1Z4Bwyw.mp3\n","      🔉 セグメント1: voice=ja-JP, text='```…'\n","      🔉 セグメント2: voice=ja-JP-Neural2-B, text='皆さん、こんにちは！Mayaです。今日も…'\n","      🔉 セグメント3: voice=ja-JP-Neural2-C, text='わーい！Mayaお姉ちゃん、Amazon…'\n","      🔉 セグメント4: voice=ja-JP-Neural2-B, text='Shibaちゃん、興味津々だね！ 今回の…'\n","      🔉 セグメント5: voice=ja-JP-Neural2-C, text='5つのステップ！なんだか難しそうだけど、…'\n","      🔉 セグメント6: voice=ja-JP-Neural2-B, text='大丈夫、一つずつ丁寧に解説していくからね…'\n","      🔉 セグメント7: voice=ja-JP-Neural2-C, text='パッケージの裏を見るのか！それって、意外…'\n","      🔉 セグメント8: voice=ja-JP-Neural2-B, text='そうなの。そして、もし直接取引が難しけれ…'\n","      🔉 セグメント9: voice=ja-JP-Neural2-C, text='なるほど！直接取引がダメでも、あきらめず…'\n","      🔉 セグメント10: voice=ja-JP-Neural2-B, text='その通り！次のポイントは、**徹底的な商…'\n","      🔉 セグメント11: voice=ja-JP-Neural2-C, text='リサーチって、具体的に何をするの？…'\n","      🔉 セグメント12: voice=ja-JP-Neural2-B, text='例えば、Amazonの商品ページで、類似…'\n","      🔉 セグメント13: voice=ja-JP-Neural2-C, text='へぇ～、いろんな方法があるんだね！それっ…'\n","      🔉 セグメント14: voice=ja-JP-Neural2-B, text='まさにそうね！そして、最後のポイントは、…'\n","      🔉 セグメント15: voice=ja-JP-Neural2-C, text='返品率とか、ネガティブなフィードバックっ…'\n","      🔉 セグメント16: voice=ja-JP-Neural2-B, text='ええ、とても大切です。なぜなら、それらは…'\n","      🔉 セグメント17: voice=ja-JP-Neural2-C, text='すごい！先を見越して動くって、かっこいい…'\n","      🔉 セグメント18: voice=ja-JP-Neural2-B, text='今回の内容を踏まえ、リスナーの皆さんが明…'\n","      🔉 セグメント19: voice=ja-JP-Neural2-C, text='それならShibaにもできそう！おやつに…'\n","      🔉 セグメント20: voice=ja-JP-Neural2-B, text='素晴らしい！Shibaちゃんの好奇心旺盛…'\n","      🔉 セグメント21: voice=ja-JP-Neural2-C, text='今日のお話、すっごく勉強になった！Shi…'\n","      🔉 セグメント22: voice=ja-JP-Neural2-B, text='Shibaちゃんの夢、応援しているわ！そ…'\n","      🔉 セグメント23: voice=ja-JP-Neural2-B, text='```…'\n","      🔗 23 チャンクを結合中...\n","   ✅ 出力完了: /content/drive/MyDrive/Colab Notebooks/00_Podcast/yt_podcast/outputs/h79B1Z4Bwyw.mp3\n","\n","   ▶️ 処理中: hLBUuQpTghA.txt → hLBUuQpTghA.mp3\n","      🔉 セグメント1: voice=ja-JP, text='```…'\n","      🔉 セグメント2: voice=ja-JP-Neural2-B, text='皆さん、こんにちは。今日も「意識高めビジ…'\n","      🔉 セグメント3: voice=ja-JP-Neural2-C, text='わーい！Mayaお姉ちゃん、今日はどんな…'\n","      🔉 セグメント4: voice=ja-JP-Neural2-B, text='そうですね、Shibaちゃん。今日の動画…'\n","      🔉 セグメント5: voice=ja-JP-Neural2-C, text='へぇ～！報酬！くぅ～ん、気になる！…'\n","      🔉 セグメント6: voice=ja-JP-Neural2-B, text='重要なポイントは３つあります。まず１つ目…'\n","      🔉 セグメント7: voice=ja-JP-Neural2-C, text='そっかぁ。途中で投げ出しちゃダメなんだね…'\n","      🔉 セグメント8: voice=ja-JP-Neural2-B, text='その通りです。２つ目のポイントは「夢を信…'\n","      🔉 セグメント9: voice=ja-JP-Neural2-C, text='なるほどね！夢を信じて頑張れば、いいこと…'\n","      🔉 セグメント10: voice=ja-JP-Neural2-B, text='日本のビジネスシーンでも、この考え方は非…'\n","      🔉 セグメント11: voice=ja-JP-Neural2-C, text='ふむふむ。会社員でもできるんだ！…'\n","      🔉 セグメント12: voice=ja-JP-Neural2-B, text='ええ、できます。夢を追いかけることは、必…'\n","      🔉 セグメント13: voice=ja-JP-Neural2-C, text='すごい！なんだか勇気が湧いてきた！…'\n","      🔉 セグメント14: voice=ja-JP-Neural2-B, text='ありがとうございます。では、今日のまとめ…'\n","      🔉 セグメント15: voice=ja-JP-Neural2-C, text='それならShibaにもできそう！おやつに…'\n","      🔉 セグメント16: voice=ja-JP-Neural2-B, text='素晴らしいですね！それでは最後に、Shi…'\n","      🔉 セグメント17: voice=ja-JP-Neural2-C, text='今日のお話を聞いて、夢を諦めないことの大…'\n","      🔉 セグメント18: voice=ja-JP-Neural2-B, text='素敵な夢ですね！Shibaちゃんの夢を応…'\n","      🔉 セグメント19: voice=ja-JP-Neural2-B, text='```…'\n","      🔗 19 チャンクを結合中...\n","   ✅ 出力完了: /content/drive/MyDrive/Colab Notebooks/00_Podcast/yt_podcast/outputs/hLBUuQpTghA.mp3\n","\n","   ▶️ 処理中: iYLUCYZl5I4.txt → iYLUCYZl5I4.mp3\n","      🔉 セグメント1: voice=ja-JP, text='```…'\n","      🔉 セグメント2: voice=ja-JP-Neural2-B, text='皆さん、こんにちは！今日も「意識高めビジ…'\n","      🔉 セグメント3: voice=ja-JP-Neural2-C, text='わーい！Mayaお姉ちゃん、今日はどんな…'\n","      🔉 セグメント4: voice=ja-JP-Neural2-B, text='そうですね、Shibaちゃん。まるで魔法…'\n","      🔉 セグメント5: voice=ja-JP-Neural2-C, text='3つも！くぅ～ん、聞きたい！聞きたい！…'\n","      🔉 セグメント6: voice=ja-JP-Neural2-B, text='まず1つ目は、「初期投資の嘘」について。…'\n","      🔉 セグメント7: voice=ja-JP-Neural2-C, text='えー！そうなの？でも、どうやってお金がな…'\n","      🔉 セグメント8: voice=ja-JP-Neural2-B, text='いい質問ですね、Shibaちゃん。ミゲル…'\n","      🔉 セグメント9: voice=ja-JP-Neural2-C, text='へぇ～、それって日本の会社でも使えるのか…'\n","      🔉 セグメント10: voice=ja-JP-Neural2-B, text='もちろんです。大企業でも、新規事業を立ち…'\n","      🔉 セグメント11: voice=ja-JP-Neural2-B, text='2つ目のポイントは、「問題を解決するビジ…'\n","      🔉 セグメント12: voice=ja-JP-Neural2-C, text='なるほど！それってつまり、困っている人を…'\n","      🔉 セグメント13: voice=ja-JP-Neural2-B, text='その通りです。例えば、高齢化が進む地域で…'\n","      🔉 セグメント14: voice=ja-JP-Neural2-B, text='そして3つ目は、「恐れを手放す」こと。多…'\n","      🔉 セグメント15: voice=ja-JP-Neural2-C, text='失敗してもいいんだ！それならShibaに…'\n","      🔉 セグメント16: voice=ja-JP-Neural2-B, text='そうですね。失敗は成功のもと、という言葉…'\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m\u003cipython-input-67-2b8762f24ae8\u003e\u001b[0m in \u001b[0;36m\u003ccell line: 0\u003e\u001b[0;34m()\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtxt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvp\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msegments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"      🔉 セグメント{idx}: voice={vp.name if vp.name else vp.language_code}, text='{txt[:20]}…'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---\u003e 60\u001b[0;31m             \u001b[0maudio_bytes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msynthesize_text_for_tts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtxt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAUDIO_CONFIG_MP3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtts_client\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m             \u001b[0maudio_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAudioSegment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mp3'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m\u003cipython-input-67-2b8762f24ae8\u003e\u001b[0m in \u001b[0;36msynthesize_text_for_tts\u001b[0;34m(text, voice_params, audio_config, client)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msynthesize_text_for_tts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvoice_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maudio_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0msynthesis_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtexttospeech\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSynthesisInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---\u003e 12\u001b[0;31m     response = client.synthesize_speech(\n\u001b[0m\u001b[1;32m     13\u001b[0m         request={\n\u001b[1;32m     14\u001b[0m             \u001b[0;34m\"input\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msynthesis_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/cloud/texttospeech_v1/services/text_to_speech/client.py\u001b[0m in \u001b[0;36msynthesize_speech\u001b[0;34m(self, request, input, voice, audio_config, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m    944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    945\u001b[0m         \u001b[0;31m# Send the request.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 946\u001b[0;31m         response = rpc(\n\u001b[0m\u001b[1;32m    947\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    948\u001b[0m             \u001b[0mretry\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/api_core/gapic_v1/method.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/api_core/grpc_helpers.py\u001b[0m in \u001b[0;36merror_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0merror_remapped_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---\u003e 76\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcallable_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mgrpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRpcError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_grpc_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/grpc/_interceptor.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0mcompression\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgrpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCompression\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m     ) -\u003e Any:\n\u001b[0;32m--\u003e 277\u001b[0;31m         response, ignored_call = self._with_call(\n\u001b[0m\u001b[1;32m    278\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m             \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/grpc/_interceptor.py\u001b[0m in \u001b[0;36m_with_call\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m    327\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_FailureOutcome\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 329\u001b[0;31m         call = self._interceptor.intercept_unary_unary(\n\u001b[0m\u001b[1;32m    330\u001b[0m             \u001b[0mcontinuation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclient_call_details\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/cloud/texttospeech_v1/services/text_to_speech/transports/grpc.py\u001b[0m in \u001b[0;36mintercept_unary_unary\u001b[0;34m(self, continuation, client_call_details, request)\u001b[0m\n\u001b[1;32m     76\u001b[0m                 },\n\u001b[1;32m     77\u001b[0m             )\n\u001b[0;32m---\u003e 78\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontinuation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclient_call_details\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlogging_enabled\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pragma: NO COVER\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0mresponse_metadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrailing_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/grpc/_interceptor.py\u001b[0m in \u001b[0;36mcontinuation\u001b[0;34m(new_details, request)\u001b[0m\n\u001b[1;32m    313\u001b[0m             ) = _unwrap_client_call_details(new_details, client_call_details)\n\u001b[1;32m    314\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 315\u001b[0;31m                 response, call = self._thunk(new_method).with_call(\n\u001b[0m\u001b[1;32m    316\u001b[0m                     \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m                     \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/grpc/_channel.py\u001b[0m in \u001b[0;36mwith_call\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m   1193\u001b[0m             \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1194\u001b[0m             \u001b[0mcall\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-\u003e 1195\u001b[0;31m         \u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_blocking\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1196\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcredentials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait_for_ready\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1197\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/grpc/_channel.py\u001b[0m in \u001b[0;36m_blocking\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m   1160\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_registered_call_handle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1161\u001b[0m             )\n\u001b[0;32m-\u003e 1162\u001b[0;31m             \u001b[0mevent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1163\u001b[0m             \u001b[0m_handle_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_response_deserializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1164\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi\u001b[0m in \u001b[0;36mgrpc._cython.cygrpc.SegregatedCall.next_event\u001b[0;34m()\u001b[0m\n","\u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi\u001b[0m in \u001b[0;36mgrpc._cython.cygrpc._next_call_event\u001b[0;34m()\u001b[0m\n","\u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi\u001b[0m in \u001b[0;36mgrpc._cython.cygrpc._next_call_event\u001b[0;34m()\u001b[0m\n","\u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/completion_queue.pyx.pxi\u001b[0m in \u001b[0;36mgrpc._cython.cygrpc._latent_event\u001b[0;34m()\u001b[0m\n","\u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/completion_queue.pyx.pxi\u001b[0m in \u001b[0;36mgrpc._cython.cygrpc._internal_latent_event\u001b[0;34m()\u001b[0m\n","\u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/completion_queue.pyx.pxi\u001b[0m in \u001b[0;36mgrpc._cython.cygrpc._interpret_event\u001b[0;34m()\u001b[0m\n","\u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/tag.pyx.pxi\u001b[0m in \u001b[0;36mgrpc._cython.cygrpc._BatchOperationTag.event\u001b[0;34m()\u001b[0m\n","\u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/operation.pyx.pxi\u001b[0m in \u001b[0;36mgrpc._cython.cygrpc.ReceiveInitialMetadataOperation.un_c\u001b[0;34m()\u001b[0m\n","\u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/metadata.pyx.pxi\u001b[0m in \u001b[0;36mgrpc._cython.cygrpc._metadata\u001b[0;34m()\u001b[0m\n","\u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/metadata.pyx.pxi\u001b[0m in \u001b[0;36mgenexpr\u001b[0;34m()\u001b[0m\n","\u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/metadata.pyx.pxi\u001b[0m in \u001b[0;36mgrpc._cython.cygrpc._metadatum\u001b[0;34m()\u001b[0m\n","\u001b[0;32m\u003cstring\u003e\u001b[0m in \u001b[0;36m\u003clambda\u003e\u001b[0;34m(_cls, key, value)\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# ========== セル 4: STEP5 本番実行 (全ファイルの音声合成＆出力) ==========\n","print(\"▶️ セル4: 本番実行を開始します...\")\n","\n","import os\n","import io\n","from pydub import AudioSegment\n","from google.cloud import texttospeech_v1 as texttospeech\n","\n","# --- ヘルパー関数はセル3と同じものを利用 ---\n","def synthesize_text_for_tts(text, voice_params, audio_config, client):\n","    synthesis_input = texttospeech.SynthesisInput(text=text)\n","    response = client.synthesize_speech(\n","        request={\n","            \"input\": synthesis_input,\n","            \"voice\": voice_params,\n","            \"audio_config\": audio_config,\n","        }\n","    )\n","    return response.audio_content\n","\n","# 台本ディレクトリの全 .txt を処理\n","script_files = sorted(f for f in os.listdir(SCRIPTS_DIR_TTS) if f.endswith('.txt'))\n","if not script_files:\n","    print(\"‼️ 本番用の台本ファイルが見つかりません。セル2でパスを確認してください。\")\n","else:\n","    for src in script_files:\n","        vid = src[:-4]\n","        out_path = os.path.join(OUTPUTS_DIR_TTS, f\"{vid}.mp3\")\n","        # 既存ファイルはスキップ\n","        if os.path.exists(out_path):\n","            print(f\"   ⏭️ スキップ: {out_path} は既に存在します。\")\n","            continue\n","\n","        print(f\"\\n   ▶️ 処理中: {src} → {vid}.mp3\")\n","        # ファイル読み込み\n","        with open(os.path.join(SCRIPTS_DIR_TTS, src), 'r', encoding='utf-8') as f:\n","            lines = [ln.strip() for ln in f if ln.strip()]\n","\n","        # 行ごとに (テキスト, VoiceSelectionParams) のリスト化\n","        segments = []\n","        current_speaker = 'Default'\n","        for line in lines:\n","            if ':' in line:\n","                tag, content = line.split(':', 1)\n","                tag = tag.strip()\n","                if tag in VOICE_SETTINGS:\n","                    current_speaker = tag\n","                    text = content.strip()\n","                else:\n","                    text = line\n","            else:\n","                text = line\n","            voice_params = VOICE_SETTINGS.get(current_speaker, VOICE_SETTINGS['Default'])\n","            segments.append((text, voice_params))\n","\n","        # 各セグメントを合成＆結合\n","        audio_list = []\n","        for idx, (txt, vp) in enumerate(segments, 1):\n","            print(f\"      🔉 セグメント{idx}: voice={vp.name if vp.name else vp.language_code}, text='{txt[:20]}…'\")\n","            audio_bytes = synthesize_text_for_tts(txt, vp, AUDIO_CONFIG_MP3, tts_client)\n","            audio_list.append(AudioSegment.from_file(io.BytesIO(audio_bytes), format='mp3'))\n","\n","        print(f\"      🔗 {len(audio_list)} チャンクを結合中...\")\n","        combined = AudioSegment.empty()\n","        for seg in audio_list:\n","            combined += seg\n","\n","        # MP3 出力\n","        combined.export(out_path, format='mp3')\n","        print(f\"   ✅ 出力完了: {out_path}\")\n","\n","print(\"\\n✅ セル4: 本番実行 完了しました。\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MndVeBPuWI9E"},"outputs":[],"source":[]}],"metadata":{"colab":{"authorship_tag":"ABX9TyMStYuE9vv9XNIsUX44kf1x","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}